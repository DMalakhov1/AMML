{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import random\n",
    "# Класс EpsGreedy из вашего файла\n",
    "class EpsGreedy:\n",
    "    def __init__(self, n_arms: int, eps: float = 0.1):\n",
    "        self.n_arms = n_arms\n",
    "        self.eps = eps\n",
    "        self.n_iters = 0\n",
    "        self.arms_states = np.zeros(n_arms)\n",
    "        self.arms_actions = np.zeros(n_arms)\n",
    "    def flush(self):\n",
    "        self.n_iters = 0\n",
    "        self.arms_states = np.zeros(self.n_arms)\n",
    "        self.arms_actions = np.zeros(self.n_arms)\n",
    "    def update_reward(self, arm: int, reward: int):\n",
    "        self.n_iters += 1\n",
    "        self.arms_states[arm] += reward\n",
    "        self.arms_actions[arm] += 1\n",
    "    def choose_arm(self):\n",
    "        if random.random() < self.eps:\n",
    "            return random.randint(0, self.n_arms - 1)\n",
    "        else:\n",
    "            return np.argmax(self.arms_states / self.arms_actions)\n",
    "        \n",
    "    def get_policy(self):\n",
    "        if np.all(self.arms_actions == 0):\n",
    "            return np.full(self.n_arms, 1.0 / self.n_arms)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            values = self.arms_states / self.arms_actions\n",
    "        values[np.isnan(values)] = 0\n",
    "        best = np.argmax(values)\n",
    "        policy = np.full(self.n_arms, self.eps / self.n_arms)\n",
    "        policy[best] += 1 - self.eps\n",
    "        return policy \n",
    "    \n",
    "class CustomFeatures(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if 'history' in X.columns and 'recency' in X.columns:\n",
    "            X['history_recency'] = X['history'] / np.clip(X['recency'], 1, None)\n",
    "        if 'mens' in X.columns and 'womens' in X.columns:\n",
    "            X['mens_womens'] = X['mens'] * X['womens']\n",
    "        if 'recency' in X.columns:\n",
    "            X['recency_bin'] = pd.cut(X['recency'], bins=[0, 3, 6, 9, 12],\n",
    "                                      labels=['very_recent', 'recent', 'medium', 'old'])\n",
    "        return X\n",
    "# Загрузим данные\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "# Константы\n",
    "ACTION_COL = 'segment'\n",
    "TARGET_COL = 'visit'\n",
    "ID_COL = 'id'\n",
    "ACTIONS = ['Mens E-Mail', 'Womens E-Mail', 'No E-Mail']\n",
    "ACTION_TO_IDX = {a: i for i, a in enumerate(ACTIONS)}\n",
    "CONTROL = 'No E-Mail'\n",
    "# Препроцессинг\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "num_log = ['history', 'history_recency']\n",
    "num_scale = ['recency']\n",
    "binary = ['mens', 'womens', 'newbie', 'mens_womens']\n",
    "# Убрали 'history_segment' отсюда\n",
    "cat = ['zip_code', 'channel', 'recency_bin']\n",
    "ct = ColumnTransformer([\n",
    "    ('num_log', Pipeline([('imp', SimpleImputer(strategy='median')),\n",
    "                          ('log', log_transformer),\n",
    "                          ('scale', MinMaxScaler())]), num_log),\n",
    "    ('num_scale', Pipeline([('imp', SimpleImputer(strategy='median')),\n",
    "                            ('scale', MinMaxScaler())]), num_scale),\n",
    "    ('binary', Pipeline([('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                         ('cast', FunctionTransformer(lambda x: x.astype(float)))]), binary),\n",
    "    ('cat', Pipeline([('imp', SimpleImputer(strategy='most_frequent', fill_value='Missing')),\n",
    "                      ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), cat),\n",
    "], remainder='drop')\n",
    "preprocess = Pipeline([\n",
    "    ('custom', CustomFeatures()),\n",
    "    ('ct', ct),\n",
    "    ('poly', poly)\n",
    "])\n",
    "action_ohe = OneHotEncoder(categories=[ACTIONS], sparse_output=False, handle_unknown='ignore')\n",
    "action_ohe.fit(np.array(ACTIONS).reshape(-1, 1))\n",
    "# Fit preprocess на train_df без history_segment (если он есть в данных)\n",
    "train_fit_df = train_df.drop(columns=['history_segment'], errors='ignore')\n",
    "preprocess.fit(train_fit_df)\n",
    "def build_X(df, action=None):\n",
    "    # Явно удаляем history_segment, чтобы не полагаться на его наличие\n",
    "    df_proc = df.drop(columns=['history_segment'], errors='ignore')\n",
    "    X = preprocess.transform(df_proc)\n",
    "    if action is not None:\n",
    "        act = action_ohe.transform(np.full((len(df_proc), 1), action))\n",
    "    else:\n",
    "        act = action_ohe.transform(df_proc[[ACTION_COL]])\n",
    "    return np.hstack([X, act])\n",
    "def get_plog(df):\n",
    "    return np.full((len(df), 3), 1.0 / 3)\n",
    "def predict_all(model, df):\n",
    "    probs = np.hstack([model.predict_proba(build_X(df, a))[:, 1].reshape(-1, 1) for a in ACTIONS])\n",
    "    control_idx = ACTIONS.index(CONTROL)\n",
    "    uplift = probs - probs[:, control_idx, None]\n",
    "    return uplift\n",
    "def compute_snips(df, pi):\n",
    "    idx = df[ACTION_COL].map(ACTION_TO_IDX).values\n",
    "    pi_ai = pi[np.arange(len(df)), idx]\n",
    "    p_log = get_plog(df)[np.arange(len(df)), idx]\n",
    "    r = df[TARGET_COL].values\n",
    "    w = pi_ai / np.clip(p_log, 1e-8, None)\n",
    "    w = np.clip(w, 0, 5)\n",
    "    return np.sum(w * r) / np.sum(w)\n",
    "# Фиксированный эпсилон\n",
    "best_eps = 0\n",
    "# Финальная модель\n",
    "X_full = build_X(train_df)\n",
    "y_full = train_df[TARGET_COL].values\n",
    "weights_full = 1.0 / get_plog(train_df)[np.arange(len(train_df)), train_df[ACTION_COL].map(ACTION_TO_IDX).values]\n",
    "estimators_final = [\n",
    "    (f'lgbm_{i}', LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.6,\n",
    "        reg_alpha=0.2,\n",
    "        reg_lambda=0.2,\n",
    "        random_state=i,\n",
    "        verbose=-1\n",
    "    )) for i in range(7)\n",
    "]\n",
    "final_model = VotingClassifier(estimators=estimators_final, voting='soft')\n",
    "final_model.fit(X_full, y_full, sample_weight=weights_full)\n",
    "# Вычисляем SNIPS на всей тренировочной выборке для оценки\n",
    "uplift_scores = predict_all(final_model, train_df)\n",
    "pi_train = np.zeros((len(train_df), 3))\n",
    "for i, score in enumerate(uplift_scores):\n",
    "    eg = EpsGreedy(n_arms=3, eps=best_eps)\n",
    "    eg.arms_actions = np.ones(3)\n",
    "    eg.arms_states = score * eg.arms_actions  # Чтобы средние были равны uplift scores\n",
    "    pi_train[i] = eg.get_policy()\n",
    "best_snips = compute_snips(train_df, pi_train)\n",
    "print(f\"\\nFixed ε = {best_eps} | SNIPS on train = {best_snips:.5f}\")\n",
    "# Тест и сабмишн\n",
    "test_uplift = predict_all(final_model, test_df)\n",
    "pi_test = np.zeros((len(test_df), 3))\n",
    "for i, score in enumerate(test_uplift):\n",
    "    eg = EpsGreedy(n_arms=3, eps=best_eps)\n",
    "    eg.arms_actions = np.ones(3)\n",
    "    eg.arms_states = score * eg.arms_actions  # Чтобы средние были равны uplift scores\n",
    "    pi_test[i] = eg.get_policy()\n",
    "sub = pd.DataFrame({\n",
    "    'id': test_df[ID_COL],\n",
    "    'p_mens_email': pi_test[:, ACTION_TO_IDX['Mens E-Mail']],\n",
    "    'p_womens_email': pi_test[:, ACTION_TO_IDX['Womens E-Mail']],\n",
    "    'p_no_email': pi_test[:, ACTION_TO_IDX['No E-Mail']]\n",
    "})\n",
    "sub.iloc[:, 1:] = sub.iloc[:, 1:].clip(1e-8, 1-1e-8)\n",
    "sub.iloc[:, 1:] /= sub.iloc[:, 1:].sum(axis=1).values.reshape(-1, 1)\n",
    "assert np.allclose(sub.iloc[:, 1:].sum(axis=1), 1.0, atol=1e-6), \"Сумма != 1\"\n",
    "sub.to_csv(\"submission_final_thanks.csv\", index=False)\n",
    "print(\"\\nsubmission_uplift_epsilon_fixed_thanks2.csv готов!\")\n",
    "print(f\"ε = {best_eps} | Ожидаемый SNIPS ≈ {best_snips:.5f}\")\n",
    "print(sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd9c84",
   "metadata": {},
   "source": [
    "# **Библиотеки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca2af4",
   "metadata": {},
   "source": [
    "# **Стыренные из семинаров функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsGreedy:\n",
    "    def __init__(self, n_arms: int, eps: float = 0.1):\n",
    "        self.n_arms = n_arms\n",
    "        self.eps = eps\n",
    "        self.n_iters = 0\n",
    "        self.arms_states = np.zeros(n_arms)\n",
    "        self.arms_actions = np.zeros(n_arms)\n",
    "    def flush(self):\n",
    "        self.n_iters = 0\n",
    "        self.arms_states = np.zeros(self.n_arms)\n",
    "        self.arms_actions = np.zeros(self.n_arms)\n",
    "    def update_reward(self, arm: int, reward: int):\n",
    "        self.n_iters += 1\n",
    "        self.arms_states[arm] += reward\n",
    "        self.arms_actions[arm] += 1\n",
    "    def choose_arm(self):\n",
    "        if random.random() < self.eps:\n",
    "            return random.randint(0, self.n_arms - 1)\n",
    "        else:\n",
    "            return np.argmax(self.arms_states / self.arms_actions)\n",
    "        \n",
    "    def get_policy(self):\n",
    "        if np.all(self.arms_actions == 0):\n",
    "            return np.full(self.n_arms, 1.0 / self.n_arms)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            values = self.arms_states / self.arms_actions\n",
    "        values[np.isnan(values)] = 0\n",
    "        best = np.argmax(values)\n",
    "        policy = np.full(self.n_arms, self.eps / self.n_arms)\n",
    "        policy[best] += 1 - self.eps\n",
    "        return policy \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d44a9c",
   "metadata": {},
   "source": [
    "# **Загрузка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060da7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7704f5",
   "metadata": {},
   "source": [
    "# **Препроцессинг**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10533d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFeatures(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if 'history' in X.columns and 'recency' in X.columns:\n",
    "            X['history_recency'] = X['history'] / np.clip(X['recency'], 1, None)\n",
    "        if 'mens' in X.columns and 'womens' in X.columns:\n",
    "            X['mens_womens'] = X['mens'] * X['womens']\n",
    "        if 'recency' in X.columns:\n",
    "            X['recency_bin'] = pd.cut(X['recency'], bins=[0, 3, 6, 9, 12],\n",
    "                                      labels=['very_recent', 'recent', 'medium', 'old'])\n",
    "        return X\n",
    "\n",
    "\n",
    "ACTION_COL = 'segment'\n",
    "TARGET_COL = 'visit'\n",
    "ID_COL = 'id'\n",
    "ACTIONS = ['Mens E-Mail', 'Womens E-Mail', 'No E-Mail']\n",
    "ACTION_TO_IDX = {a: i for i, a in enumerate(ACTIONS)}\n",
    "CONTROL = 'No E-Mail'\n",
    "\n",
    "# Препроцессинг\n",
    "log_transformer = FunctionTransformer(np.log1p)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "num_log = ['history', 'history_recency']\n",
    "num_scale = ['recency']\n",
    "binary = ['mens', 'womens', 'newbie', 'mens_womens']\n",
    "\n",
    "cat = ['zip_code', 'channel', 'recency_bin']\n",
    "ct = ColumnTransformer([\n",
    "    ('num_log', Pipeline([('imp', SimpleImputer(strategy='median')),\n",
    "                          ('log', log_transformer),\n",
    "                          ('scale', MinMaxScaler())]), num_log),\n",
    "    ('num_scale', Pipeline([('imp', SimpleImputer(strategy='median')),\n",
    "                            ('scale', MinMaxScaler())]), num_scale),\n",
    "    ('binary', Pipeline([('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                         ('cast', FunctionTransformer(lambda x: x.astype(float)))]), binary),\n",
    "    ('cat', Pipeline([('imp', SimpleImputer(strategy='most_frequent', fill_value='Missing')),\n",
    "                      ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), cat),\n",
    "], remainder='drop')\n",
    "preprocess = Pipeline([\n",
    "    ('custom', CustomFeatures()),\n",
    "    ('ct', ct),\n",
    "    ('poly', poly)\n",
    "])\n",
    "action_ohe = OneHotEncoder(categories=[ACTIONS], sparse_output=False, handle_unknown='ignore')\n",
    "action_ohe.fit(np.array(ACTIONS).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229da87",
   "metadata": {},
   "source": [
    "# **Финальная модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67913d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_df = train_df.drop(columns=['history_segment'], errors='ignore')\n",
    "preprocess.fit(train_fit_df)\n",
    "def build_X(df, action=None):\n",
    "    # Явно удаляем history_segment, чтобы не полагаться на его наличие\n",
    "    df_proc = df.drop(columns=['history_segment'], errors='ignore')\n",
    "    X = preprocess.transform(df_proc)\n",
    "    if action is not None:\n",
    "        act = action_ohe.transform(np.full((len(df_proc), 1), action))\n",
    "    else:\n",
    "        act = action_ohe.transform(df_proc[[ACTION_COL]])\n",
    "    return np.hstack([X, act])\n",
    "def get_plog(df):\n",
    "    return np.full((len(df), 3), 1.0 / 3)\n",
    "def predict_all(model, df):\n",
    "    probs = np.hstack([model.predict_proba(build_X(df, a))[:, 1].reshape(-1, 1) for a in ACTIONS])\n",
    "    control_idx = ACTIONS.index(CONTROL)\n",
    "    uplift = probs - probs[:, control_idx, None]\n",
    "    return uplift\n",
    "def compute_snips(df, pi):\n",
    "    idx = df[ACTION_COL].map(ACTION_TO_IDX).values\n",
    "    pi_ai = pi[np.arange(len(df)), idx]\n",
    "    p_log = get_plog(df)[np.arange(len(df)), idx]\n",
    "    r = df[TARGET_COL].values\n",
    "    w = pi_ai / np.clip(p_log, 1e-8, None)\n",
    "    w = np.clip(w, 0, 5)\n",
    "    return np.sum(w * r) / np.sum(w)\n",
    "# Фиксированный эпсилон\n",
    "best_eps = 0\n",
    "# Финальная модель\n",
    "X_full = build_X(train_df)\n",
    "y_full = train_df[TARGET_COL].values\n",
    "weights_full = 1.0 / get_plog(train_df)[np.arange(len(train_df)), train_df[ACTION_COL].map(ACTION_TO_IDX).values]\n",
    "estimators_final = [\n",
    "    (f'lgbm_{i}', LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.6,\n",
    "        reg_alpha=0.2,\n",
    "        reg_lambda=0.2,\n",
    "        random_state=i,\n",
    "        verbose=-1\n",
    "    )) for i in range(7)\n",
    "]\n",
    "final_model = VotingClassifier(estimators=estimators_final, voting='soft')\n",
    "final_model.fit(X_full, y_full, sample_weight=weights_full)\n",
    "# Вычисляем SNIPS на всей тренировочной выборке для оценки\n",
    "uplift_scores = predict_all(final_model, train_df)\n",
    "pi_train = np.zeros((len(train_df), 3))\n",
    "for i, score in enumerate(uplift_scores):\n",
    "    eg = EpsGreedy(n_arms=3, eps=best_eps)\n",
    "    eg.arms_actions = np.ones(3)\n",
    "    eg.arms_states = score * eg.arms_actions  # Чтобы средние были равны uplift scores\n",
    "    pi_train[i] = eg.get_policy()\n",
    "best_snips = compute_snips(train_df, pi_train)\n",
    "print(f\"\\nFixed ε = {best_eps} | SNIPS on train = {best_snips:.5f}\")\n",
    "# Тест и сабмишн\n",
    "test_uplift = predict_all(final_model, test_df)\n",
    "pi_test = np.zeros((len(test_df), 3))\n",
    "for i, score in enumerate(test_uplift):\n",
    "    eg = EpsGreedy(n_arms=3, eps=best_eps)\n",
    "    eg.arms_actions = np.ones(3)\n",
    "    eg.arms_states = score * eg.arms_actions  # Чтобы средние были равны uplift scores\n",
    "    pi_test[i] = eg.get_policy()\n",
    "sub = pd.DataFrame({\n",
    "    'id': test_df[ID_COL],\n",
    "    'p_mens_email': pi_test[:, ACTION_TO_IDX['Mens E-Mail']],\n",
    "    'p_womens_email': pi_test[:, ACTION_TO_IDX['Womens E-Mail']],\n",
    "    'p_no_email': pi_test[:, ACTION_TO_IDX['No E-Mail']]\n",
    "})\n",
    "sub.iloc[:, 1:] = sub.iloc[:, 1:].clip(1e-8, 1-1e-8)\n",
    "sub.iloc[:, 1:] /= sub.iloc[:, 1:].sum(axis=1).values.reshape(-1, 1)\n",
    "assert np.allclose(sub.iloc[:, 1:].sum(axis=1), 1.0, atol=1e-6), \"Сумма != 1\"\n",
    "sub.to_csv(\"submission_final_thanks.csv\", index=False)\n",
    "print(\"\\nsubmission_uplift_epsilon_fixed_thanks2.csv готов!\")\n",
    "print(f\"ε = {best_eps} | Ожидаемый SNIPS ≈ {best_snips:.5f}\")\n",
    "print(sub.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

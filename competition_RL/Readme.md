# Overview

Это учебное соревнование по оффлайн-обучению политик (RL в форме контекстных бандитов)  
на основе классического датасета по e-mail маркетингу.


## Description


<details>
<summary>1) Постановка задачи</summary>

Вам нужно построить политику, которая, видя контекст пользователя, назначает распределение вероятностей по действиям, чтобы максимизировать вероятность визита.

**Почему это не обычная классификация/регрессия?**

- В train мы наблюдаем пары, где — назначенное в эксперименте действие, а не ваше прогнозируемое действие.  
- Мы не видим контрфакты: что было бы с тем же пользователем при другом действии.  
- Обычная модель «предскажи visit» не отвечает на вопрос выбора действия и даёт смещённую оценку качества.  
- Нужен оффлайн-RL/контекстные бандиты: обучение политики и её оценка по логам с помощью методов важностного взвешивания (IPS/SNIPS), корректирующих разницу между вашей политикой и логирующей.  

Ключевой объект — политика, то есть вектор вероятностей по 3 действиям для каждого объекта.
</details>

<details>
<summary>2) Таргет</summary>

- **Reward:** бинарная переменная `visit` (защумлённая), показывающая, был ли визит.  
- **Цель:** максимизировать ожидаемую вероятность визита при выборе действий по политике.  

**Что должен сделать участник:**
- Построить модель(и), оценивающую полезность действий.  
- Сформировать стохастическую политику — вероятности по всем трём действиям, суммирующиеся в 1.  
- Сгенерировать `submission.csv` в требуемом формате (см. ниже).
</details>

---

## Evaluation


<details>
<summary>1) Метрика качества</summary>

**Обозначения:**
- — контекст  
- — действия (что реально делали в рассылке)  
- — reward  
- — пропенсити логирующей политики (в нашем случае)  
- — ваша политика (предсказываемый вектор вероятностей)

### 1.1 Self-Normalized IPS (SNIPS) — оценка значения политики

Где …  

Смысл: мы «перевзвешиваем» наблюдения тем сильнее, чем чаще ваша политика выбирала бы то же действие, что и логирующая.

### 1.2 Бенчмарк «лучшая статическая политика»

Рассмотрим три статические политики, выбирающие один фиксированный arm всегда, и оценим их IPS-значения.  
Тогда …

### 1.3 Итоговый скор

Чем выше score, тем лучше.  
Позитивный score означает, что ваша политика превосходит любую «один-arm» стратегию.  
Лидерборд «Public»/«Private» считается на соответствующих подмножествах теста.

### 1.4 Примечания
- Проверки валидности сабмита: каждая строка — три вероятности и их сумма ровно 1.  
- Не используйте `segment` как признак — это действие. В тесте его нет по определению.
</details>

<details>
<summary>2) Формат решения (submission)</summary>

**Файл:** `submission.csv`  

**Колонки (строго в таком виде):**
- `id` — идентификатор из test.csv  
- `p_mens_email` — …  
- `p_womens_email` — …  
- `p_no_email` — …  

Каждая строка — распределение вероятностей по трём действиям.

**Пример:**
```csv
id,p_mens_email,p_womens_email,p_no_email
100001,0.10,0.80,0.10
100002,0.33,0.33,0.34
100003,0.70,0.10,0.20
...
